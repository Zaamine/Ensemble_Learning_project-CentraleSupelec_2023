{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3096\\459140566.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Display the listings using an image of a map of New York ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "### Display the listings using an image of a map of New York ###\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy = df_copy.loc[df_copy['price'] != 0]\n",
    "df_copy = df_copy.loc[df_copy['price'] <= 250]\n",
    "df_copy = df_copy.loc[df_copy['availability_365'] != 0]\n",
    "\n",
    "plt.figure(figsize = (15, 15))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Load the image\n",
    "nyc_image = Image.open(\"New_York_City_.png\")\n",
    "\n",
    "# Plot the data using longitude and latitude\n",
    "df_copy.plot(kind = 'scatter', x = 'longitude', y = 'latitude', label = 'Listing', c = 'price', ax = ax, \n",
    "        cmap = plt.get_cmap('jet'), colorbar = True, alpha = 0.4)\n",
    "\n",
    "# Set the extent of the image to correctly display it\n",
    "ax.imshow(nyc_image, extent = [-74.258, -73.7, 40.49, 40.92]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we experimented and tuned many ensemble algorithm in the kaggle Airbnb dataset. We even developped our own voting and stacking algorithms in the process.\n",
    "\n",
    "## Feature Engineering : \n",
    "1. In the 'functions' folder can be found more than 600 lines of helper functions in the file 'functions.py' : \n",
    " - get_cartesian: Converts latitude and longitude arrays into (x,y,z) coordinates\n",
    " - lambda_n : Compute the blending factor using a sigmoid function.\n",
    " - target_encoding: Target encoding using blending factor and accounting for hierarchy.\n",
    " - clean_text: A function to remove stop words and special characters\n",
    " - process_batch : Function to encode a single batch of texts\n",
    " - encode_texts : Function to encode many texts by batches\n",
    " - compare_norm_dist : Compares a series normal distribution and return threshold to remove outliers.\n",
    " - preprocess :  Preprocesses raw file to return a feature matrix X (dataframe) and target values y (dataframe)\n",
    " - scores : Compute MAE, MSE, RMSE, R2 and MAPE scores and plot prediction errors\n",
    " - load_params : load json files containing tuned models' parameters\n",
    " - vote_prediction : Homemade voting algorithm that computes predictions and make a weighted sum or average\n",
    " - stacking_prediction : Homemade stacking algorithm that computes predictions on k-fold to feed a final metamodel (linear regression)\n",
    "2. Target encoding of the fields 'host_id' and 'neighborhood' (+200 categories), with integration of a blending factor function to address underrepresented categories, as suggested by Micci-Barreca (2001).\n",
    "3. One-hot encoding of the other categorical fields.\n",
    "4. Integration of external features through an opendata Airbnb dataset (https://public.opendatasoft.com/explore/dataset/airbnb-listings/table/?refine.city=New+York):\n",
    " - Number of beds\n",
    " - Number of rooms\n",
    " - Number of bathrooms\n",
    " - Square meters\n",
    " - Accommodates\n",
    " - Textual Descriptions \n",
    " - Host Response Rate\n",
    " - Type of bed\n",
    " - etc.\n",
    "5. Encoding Seq2Vec of textual fields using a pretrained NLP model made available in spaCy package, followed by T-SNE embedding in 2-D.\n",
    " - We have made available a separate notebook for that in folder 'seq2vec_tsne'\n",
    "6. Elimination of outliers that are more than 3 standard deviations from the mean of log(log(price)) (double log makes the points closer to a Normal distribution). \n",
    "\n",
    "\n",
    "## Models Experimented and Tuned: \n",
    "\n",
    "We have used all the ensemble models seen in class and have also coded our own algorithms for Voting and Stacking (Two other well-known ensemble techniques) that we compared with sklearn's implementation.\n",
    "\n",
    "Our algorithms seemed to have equal or better performances in a faster time, most notably for Stacking were our implementation slightly differs with sklearn's one.\n",
    "\n",
    "\n",
    "In the folder 'models' can be found individual notebooks detailing the training, hyperparameter tuning approach and the performances pre and post tuning of each models. We computed evaluation metrics for both 'Price' and 'log(Price)' but only kept into account the former, as it is the actual target variable of interest ( log(price) having conceptually no meaning): \n",
    " - decision tree\n",
    " - bagging\n",
    " - random forest\n",
    " - extremely randomized forest\n",
    " - adaboost\n",
    " - catboost\n",
    " - sklearn gradient boosting\n",
    " - sklearn hist gradient boosting\n",
    " - LightGBM\n",
    " - XGBoost\n",
    " - Voting    (Weights tuned with hyperopt)\n",
    " - Stacking\n",
    "\n",
    "We have optimized the hyperparameters of all these models with the hyperopt package, which relies on Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from functions.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = preprocess(file_paths_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3619, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected Features\n",
    "selected_features = ['minimum_nights', \n",
    "                     'number_of_reviews', \n",
    "                     'reviews_per_month', \n",
    "                     'calculated_host_listings_count', \n",
    "                     'availability_365',\n",
    "                     'Host Response Rate', \n",
    "                     'Accommodates', \n",
    "                     'Bathrooms', \n",
    "                     'Bedrooms', \n",
    "                     'Beds', \n",
    "                     'Square Feet',\n",
    "                     'recency_last_review' ,\n",
    "                     'last_review_day', \n",
    "                     'last_review_month', \n",
    "                     'last_review_year', \n",
    "                     'room_type_Entire home/apt', \n",
    "                     'room_type_Private room', \n",
    "                     'room_type_Shared room',\n",
    "                     'mean_target_neighbourhood',\n",
    "                     'mean_target_neighbourhood_group',\n",
    "                     'neighbourhood_group_Bronx', \n",
    "                     'neighbourhood_group_Brooklyn',\n",
    "                     'neighbourhood_group_Manhattan',\n",
    "                     'neighbourhood_group_Queens',\n",
    "                     'neighbourhood_group_Staten Island',\n",
    "                     'x', \n",
    "                     'y', \n",
    "                     'z',\n",
    "                     'text_encoding_tsne_1',\n",
    "                     'text_encoding_tsne_2']\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "\n",
    "X_train_np = X_train_selected.to_numpy()\n",
    "X_test_np = X_test_selected.to_numpy()\n",
    "X_val_np = X_val_selected.to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_np)\n",
    "X_test_np = scaler.transform(X_test_np)\n",
    "X_val_np = scaler.transform(X_val_np)\n",
    "\n",
    "y_train_np = y_train.to_numpy().flatten()\n",
    "y_test_np = y_test.to_numpy().flatten()\n",
    "y_val_np = y_val.to_numpy().flatten()\n",
    "\n",
    "X_test_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeRegressor(**load_params('models/saved_models/decision_tree_params.json'))\n",
    "\n",
    "# Bagging\n",
    "bagging = BaggingRegressor(**load_params('models/saved_models/bagging_params.json'))\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestRegressor(**load_params('models/saved_models/random_forest_params.json'))\n",
    "\n",
    "# Extremely randomized tree\n",
    "extra_forest = ExtraTreesRegressor(**load_params('models/saved_models/extremely_randomized_forest_params.json'))\n",
    "\n",
    "# Adaboost\n",
    "adaboost = AdaBoostRegressor(**load_params('models/saved_models/adaboost_params.json'))\n",
    "\n",
    "# sklearn gradient boosting\n",
    "sk_gb = GradientBoostingRegressor(**load_params('models/saved_models/sk_gradient_boosting_params.json'))\n",
    "\n",
    "# sklearn hist gradient boosting\n",
    "hist_sk_gb = HistGradientBoostingRegressor(**load_params('models/saved_models/sk_hist_gradient_boosting_params.json'))\n",
    "\n",
    "# lgbm\n",
    "lgbm = LGBMRegressor(**load_params('models/saved_models/lgbm_params.json'))\n",
    "\n",
    "# XGBOOST\n",
    "xgb = xg.XGBRegressor(**load_params('models/saved_models/xgb_params.json'))\n",
    "\n",
    "# CatBoost\n",
    "catboost = CatBoostRegressor(**load_params('models/saved_models/catboost_params.json'))\n",
    "\n",
    "# Voting\n",
    "vote_weights = load_params('models/saved_models/vote_params.json')\n",
    "weights_normalized = [w/sum(vote_weights.values()) for w in vote_weights.values()]\n",
    "vote_estimators = [ ('xgb',xgb),('lgbm', lgbm),('hist_sk_gb', hist_sk_gb),('extra_forest', extra_forest),('random_forest', random_forest)]\n",
    "\n",
    "# Stacking (Due to long runtime +5 minutes, we preferred to load the scores directly)\n",
    "# Check stacking notebook in 'models' folder for detailed implementation\n",
    "homemade_stacking_scores = load_params('models/saved_scores/homemade_stacking_scores.json')\n",
    "sk_stacking_scores = load_params('models/saved_scores/sk_stacking_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Decision Tree ---\n",
      "\n",
      "R²: 0.47807739666812765\n",
      "MAE: 45.8255977175727\n",
      "MSE: 4669.256527186797\n",
      "RMSE: 68.33195831517487\n",
      "MAPE: 0.3711947323149145\n",
      "error_ratio_rmse: 0.4940511628247337\n",
      "error_ratio_mae: 0.33132651833391724\n",
      "\n",
      "\n",
      "--- Bagging ---\n",
      "\n",
      "R²: 0.5544971901954285\n",
      "MAE: 41.776126217532465\n",
      "MSE: 3985.5850068201553\n",
      "RMSE: 63.13148981942494\n",
      "MAPE: 0.3321188897694259\n",
      "error_ratio_rmse: 0.45645093050433105\n",
      "error_ratio_mae: 0.30204818133393396\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "\n",
      "R²: 0.5627451113355987\n",
      "MAE: 41.07743077885374\n",
      "MSE: 3911.796940594226\n",
      "RMSE: 62.54435978243143\n",
      "MAPE: 0.32214093099511787\n",
      "error_ratio_rmse: 0.4522058849259789\n",
      "error_ratio_mae: 0.2969964997715909\n",
      "\n",
      "\n",
      "--- Extremely Randomized Forest ---\n",
      "\n",
      "R²: 0.5617499201528038\n",
      "MAE: 41.06960290091395\n",
      "MSE: 3920.700181987488\n",
      "RMSE: 62.61549474361349\n",
      "MAPE: 0.325223859631188\n",
      "error_ratio_rmse: 0.45272020225502996\n",
      "error_ratio_mae: 0.296939902942026\n",
      "\n",
      "\n",
      "--- Adaboost ---\n",
      "\n",
      "R²: 0.4260360827605809\n",
      "MAE: 48.83235880720346\n",
      "MSE: 5134.831773583393\n",
      "RMSE: 71.65774050012597\n",
      "MAPE: 0.4034292026253855\n",
      "error_ratio_rmse: 0.5180971084743256\n",
      "error_ratio_mae: 0.3530658896221882\n",
      "\n",
      "\n",
      "--- sklearn Gradient Boosting ---\n",
      "\n",
      "R²: 0.5359911869261453\n",
      "MAE: 42.52233386554914\n",
      "MSE: 4151.144566811651\n",
      "RMSE: 64.42937658251593\n",
      "MAPE: 0.3375701698741177\n",
      "error_ratio_rmse: 0.4658348627130693\n",
      "error_ratio_mae: 0.3074433838907072\n",
      "\n",
      "\n",
      "--- sklearn Hist Gradient Boosting ---\n",
      "\n",
      "R²: 0.5590201629240139\n",
      "MAE: 41.26763181495195\n",
      "MSE: 3945.1213062629936\n",
      "RMSE: 62.81020065453536\n",
      "MAPE: 0.3194050595601385\n",
      "error_ratio_rmse: 0.4541279576314544\n",
      "error_ratio_mae: 0.29837168417098087\n",
      "\n",
      "\n",
      "--- LightGBM ---\n",
      "\n",
      "R²: 0.5675034231870559\n",
      "MAE: 40.89373140363327\n",
      "MSE: 3869.227834506519\n",
      "RMSE: 62.203117562599054\n",
      "MAPE: 0.316005849752657\n",
      "error_ratio_rmse: 0.44973864822341775\n",
      "error_ratio_mae: 0.295668323436892\n",
      "\n",
      "\n",
      "--- XGBoost ---\n",
      "\n",
      "R²: 0.5698804077601658\n",
      "MAE: 40.756570707997355\n",
      "MSE: 3847.9627069528105\n",
      "RMSE: 62.03194908233023\n",
      "MAPE: 0.31542625235815186\n",
      "error_ratio_rmse: 0.4485010722955378\n",
      "error_ratio_mae: 0.2946766293183038\n",
      "\n",
      "\n",
      "--- CatBoost ---\n",
      "\n",
      "0:\tlearn: 91.9812238\ttotal: 242ms\tremaining: 1m 21s\n",
      "1:\tlearn: 89.6813391\ttotal: 318ms\tremaining: 53.7s\n",
      "2:\tlearn: 87.6436951\ttotal: 391ms\tremaining: 43.8s\n",
      "3:\tlearn: 85.6466989\ttotal: 454ms\tremaining: 38s\n",
      "4:\tlearn: 83.9458371\ttotal: 516ms\tremaining: 34.5s\n",
      "5:\tlearn: 82.2857780\ttotal: 580ms\tremaining: 32.2s\n",
      "6:\tlearn: 80.7474130\ttotal: 636ms\tremaining: 30.2s\n",
      "7:\tlearn: 79.4880145\ttotal: 670ms\tremaining: 27.7s\n",
      "8:\tlearn: 78.4289156\ttotal: 686ms\tremaining: 25.1s\n",
      "9:\tlearn: 77.2179813\ttotal: 746ms\tremaining: 24.5s\n",
      "10:\tlearn: 76.1377550\ttotal: 800ms\tremaining: 23.9s\n",
      "11:\tlearn: 75.1150676\ttotal: 857ms\tremaining: 23.4s\n",
      "12:\tlearn: 74.2014450\ttotal: 946ms\tremaining: 23.7s\n",
      "13:\tlearn: 73.3189951\ttotal: 1.01s\tremaining: 23.5s\n",
      "14:\tlearn: 72.6561277\ttotal: 1.07s\tremaining: 23.1s\n",
      "15:\tlearn: 71.9586834\ttotal: 1.12s\tremaining: 22.6s\n",
      "16:\tlearn: 71.3248665\ttotal: 1.19s\tremaining: 22.6s\n",
      "17:\tlearn: 70.7783589\ttotal: 1.26s\tremaining: 22.4s\n",
      "18:\tlearn: 70.2887785\ttotal: 1.31s\tremaining: 22.1s\n",
      "19:\tlearn: 69.8062203\ttotal: 1.38s\tremaining: 22s\n",
      "20:\tlearn: 69.3529526\ttotal: 1.44s\tremaining: 21.8s\n",
      "21:\tlearn: 68.9634256\ttotal: 1.5s\tremaining: 21.6s\n",
      "22:\tlearn: 68.6010359\ttotal: 1.56s\tremaining: 21.4s\n",
      "23:\tlearn: 68.2019947\ttotal: 1.62s\tremaining: 21.3s\n",
      "24:\tlearn: 67.8375938\ttotal: 1.71s\tremaining: 21.5s\n",
      "25:\tlearn: 67.5406433\ttotal: 1.79s\tremaining: 21.6s\n",
      "26:\tlearn: 67.2794752\ttotal: 1.87s\tremaining: 21.6s\n",
      "27:\tlearn: 66.9567381\ttotal: 1.95s\tremaining: 21.7s\n",
      "28:\tlearn: 66.6919781\ttotal: 2.05s\tremaining: 21.9s\n",
      "29:\tlearn: 66.4299353\ttotal: 2.13s\tremaining: 22s\n",
      "30:\tlearn: 66.1738176\ttotal: 2.23s\tremaining: 22.2s\n",
      "31:\tlearn: 65.8981703\ttotal: 2.32s\tremaining: 22.2s\n",
      "32:\tlearn: 65.7302533\ttotal: 2.4s\tremaining: 22.3s\n",
      "33:\tlearn: 65.4726222\ttotal: 2.53s\tremaining: 22.7s\n",
      "34:\tlearn: 65.2977003\ttotal: 2.61s\tremaining: 22.7s\n",
      "35:\tlearn: 65.1182890\ttotal: 2.67s\tremaining: 22.5s\n",
      "36:\tlearn: 64.9484532\ttotal: 2.73s\tremaining: 22.3s\n",
      "37:\tlearn: 64.8191830\ttotal: 2.8s\tremaining: 22.2s\n",
      "38:\tlearn: 64.7247393\ttotal: 2.86s\tremaining: 22s\n",
      "39:\tlearn: 64.6083564\ttotal: 2.96s\tremaining: 22.1s\n",
      "40:\tlearn: 64.3980558\ttotal: 3.05s\tremaining: 22.2s\n",
      "41:\tlearn: 64.2896939\ttotal: 3.12s\tremaining: 22.1s\n",
      "42:\tlearn: 64.1456453\ttotal: 3.19s\tremaining: 21.9s\n",
      "43:\tlearn: 63.9907937\ttotal: 3.25s\tremaining: 21.8s\n",
      "44:\tlearn: 63.8805268\ttotal: 3.3s\tremaining: 21.6s\n",
      "45:\tlearn: 63.7291898\ttotal: 3.36s\tremaining: 21.4s\n",
      "46:\tlearn: 63.6136689\ttotal: 3.42s\tremaining: 21.2s\n",
      "47:\tlearn: 63.5059895\ttotal: 3.49s\tremaining: 21.1s\n",
      "48:\tlearn: 63.3569580\ttotal: 3.55s\tremaining: 21s\n",
      "49:\tlearn: 63.2348902\ttotal: 3.6s\tremaining: 20.8s\n",
      "50:\tlearn: 63.0685081\ttotal: 3.67s\tremaining: 20.7s\n",
      "51:\tlearn: 62.9876203\ttotal: 3.73s\tremaining: 20.6s\n",
      "52:\tlearn: 62.9247920\ttotal: 3.78s\tremaining: 20.4s\n",
      "53:\tlearn: 62.8678224\ttotal: 3.84s\tremaining: 20.3s\n",
      "54:\tlearn: 62.8176971\ttotal: 3.9s\tremaining: 20.1s\n",
      "55:\tlearn: 62.7561322\ttotal: 3.97s\tremaining: 20.1s\n",
      "56:\tlearn: 62.6415521\ttotal: 4.02s\tremaining: 19.9s\n",
      "57:\tlearn: 62.5431638\ttotal: 4.09s\tremaining: 19.8s\n",
      "58:\tlearn: 62.4887257\ttotal: 4.18s\tremaining: 19.9s\n",
      "59:\tlearn: 62.4093023\ttotal: 4.25s\tremaining: 19.8s\n",
      "60:\tlearn: 62.3223832\ttotal: 4.33s\tremaining: 19.8s\n",
      "61:\tlearn: 62.2379616\ttotal: 4.47s\tremaining: 20s\n",
      "62:\tlearn: 62.1971200\ttotal: 4.56s\tremaining: 20s\n",
      "63:\tlearn: 62.1212788\ttotal: 4.63s\tremaining: 19.9s\n",
      "64:\tlearn: 62.0304403\ttotal: 4.8s\tremaining: 20.2s\n",
      "65:\tlearn: 61.9501381\ttotal: 4.9s\tremaining: 20.3s\n",
      "66:\tlearn: 61.8851442\ttotal: 4.97s\tremaining: 20.2s\n",
      "67:\tlearn: 61.8508634\ttotal: 5.03s\tremaining: 20.1s\n",
      "68:\tlearn: 61.7580846\ttotal: 5.1s\tremaining: 20s\n",
      "69:\tlearn: 61.7110239\ttotal: 5.16s\tremaining: 19.8s\n",
      "70:\tlearn: 61.6869731\ttotal: 5.22s\tremaining: 19.7s\n",
      "71:\tlearn: 61.6175695\ttotal: 5.29s\tremaining: 19.6s\n",
      "72:\tlearn: 61.5609559\ttotal: 5.49s\tremaining: 20s\n",
      "73:\tlearn: 61.5301466\ttotal: 5.7s\tremaining: 20.4s\n",
      "74:\tlearn: 61.4189386\ttotal: 5.78s\tremaining: 20.4s\n",
      "75:\tlearn: 61.4121184\ttotal: 5.8s\tremaining: 20.1s\n",
      "76:\tlearn: 61.3699524\ttotal: 5.88s\tremaining: 20s\n",
      "77:\tlearn: 61.3240528\ttotal: 5.97s\tremaining: 20s\n",
      "78:\tlearn: 61.2555987\ttotal: 6.05s\tremaining: 19.9s\n",
      "79:\tlearn: 61.1826060\ttotal: 6.12s\tremaining: 19.8s\n",
      "80:\tlearn: 61.1361534\ttotal: 6.18s\tremaining: 19.7s\n",
      "81:\tlearn: 61.0955630\ttotal: 6.26s\tremaining: 19.6s\n",
      "82:\tlearn: 61.0539471\ttotal: 6.33s\tremaining: 19.5s\n",
      "83:\tlearn: 60.9996510\ttotal: 6.4s\tremaining: 19.4s\n",
      "84:\tlearn: 60.9238517\ttotal: 6.46s\tremaining: 19.3s\n",
      "85:\tlearn: 60.8975244\ttotal: 6.52s\tremaining: 19.2s\n",
      "86:\tlearn: 60.8334719\ttotal: 6.58s\tremaining: 19.1s\n",
      "87:\tlearn: 60.8035028\ttotal: 6.64s\tremaining: 18.9s\n",
      "88:\tlearn: 60.7178540\ttotal: 6.71s\tremaining: 18.8s\n",
      "89:\tlearn: 60.6867448\ttotal: 6.77s\tremaining: 18.7s\n",
      "90:\tlearn: 60.6212512\ttotal: 6.83s\tremaining: 18.6s\n",
      "91:\tlearn: 60.5561525\ttotal: 6.89s\tremaining: 18.5s\n",
      "92:\tlearn: 60.5261226\ttotal: 6.95s\tremaining: 18.4s\n",
      "93:\tlearn: 60.4850179\ttotal: 7.01s\tremaining: 18.3s\n",
      "94:\tlearn: 60.4369269\ttotal: 7.06s\tremaining: 18.1s\n",
      "95:\tlearn: 60.4007469\ttotal: 7.13s\tremaining: 18s\n",
      "96:\tlearn: 60.3671112\ttotal: 7.18s\tremaining: 17.9s\n",
      "97:\tlearn: 60.2951740\ttotal: 7.25s\tremaining: 17.8s\n",
      "98:\tlearn: 60.2637757\ttotal: 7.3s\tremaining: 17.7s\n",
      "99:\tlearn: 60.2261602\ttotal: 7.37s\tremaining: 17.6s\n",
      "100:\tlearn: 60.1743082\ttotal: 7.42s\tremaining: 17.5s\n",
      "101:\tlearn: 60.1316229\ttotal: 7.49s\tremaining: 17.4s\n",
      "102:\tlearn: 60.0942204\ttotal: 7.55s\tremaining: 17.3s\n",
      "103:\tlearn: 60.0470334\ttotal: 7.63s\tremaining: 17.2s\n",
      "104:\tlearn: 59.9839910\ttotal: 7.73s\tremaining: 17.2s\n",
      "105:\tlearn: 59.9310978\ttotal: 7.82s\tremaining: 17.2s\n",
      "106:\tlearn: 59.9145588\ttotal: 7.91s\tremaining: 17.1s\n",
      "107:\tlearn: 59.8263692\ttotal: 7.99s\tremaining: 17.1s\n",
      "108:\tlearn: 59.7947274\ttotal: 8.07s\tremaining: 17s\n",
      "109:\tlearn: 59.7753578\ttotal: 8.17s\tremaining: 17s\n",
      "110:\tlearn: 59.7098381\ttotal: 8.27s\tremaining: 17s\n",
      "111:\tlearn: 59.6534313\ttotal: 8.4s\tremaining: 17s\n",
      "112:\tlearn: 59.6136464\ttotal: 8.52s\tremaining: 17s\n",
      "113:\tlearn: 59.5914176\ttotal: 8.58s\tremaining: 16.9s\n",
      "114:\tlearn: 59.5701734\ttotal: 8.64s\tremaining: 16.8s\n",
      "115:\tlearn: 59.5344512\ttotal: 8.7s\tremaining: 16.7s\n",
      "116:\tlearn: 59.4952943\ttotal: 8.77s\tremaining: 16.6s\n",
      "117:\tlearn: 59.4446797\ttotal: 8.83s\tremaining: 16.5s\n",
      "118:\tlearn: 59.4134838\ttotal: 8.9s\tremaining: 16.4s\n",
      "119:\tlearn: 59.3693586\ttotal: 8.96s\tremaining: 16.3s\n",
      "120:\tlearn: 59.3337079\ttotal: 9.03s\tremaining: 16.3s\n",
      "121:\tlearn: 59.3132059\ttotal: 9.09s\tremaining: 16.2s\n",
      "122:\tlearn: 59.2999015\ttotal: 9.16s\tremaining: 16.1s\n",
      "123:\tlearn: 59.2293392\ttotal: 9.21s\tremaining: 16s\n",
      "124:\tlearn: 59.1786628\ttotal: 9.27s\tremaining: 15.9s\n",
      "125:\tlearn: 59.1488904\ttotal: 9.33s\tremaining: 15.8s\n",
      "126:\tlearn: 59.1085491\ttotal: 9.4s\tremaining: 15.7s\n",
      "127:\tlearn: 59.0101148\ttotal: 9.47s\tremaining: 15.6s\n",
      "128:\tlearn: 58.9780729\ttotal: 9.53s\tremaining: 15.5s\n",
      "129:\tlearn: 58.9504941\ttotal: 9.6s\tremaining: 15.4s\n",
      "130:\tlearn: 58.9212604\ttotal: 9.66s\tremaining: 15.3s\n",
      "131:\tlearn: 58.8791600\ttotal: 9.72s\tremaining: 15.2s\n",
      "132:\tlearn: 58.8393688\ttotal: 9.78s\tremaining: 15.2s\n",
      "133:\tlearn: 58.7340234\ttotal: 9.85s\tremaining: 15.1s\n",
      "134:\tlearn: 58.7088297\ttotal: 9.92s\tremaining: 15s\n",
      "135:\tlearn: 58.6675090\ttotal: 9.97s\tremaining: 14.9s\n",
      "136:\tlearn: 58.6456143\ttotal: 10s\tremaining: 14.8s\n",
      "137:\tlearn: 58.5561717\ttotal: 10.1s\tremaining: 14.7s\n",
      "138:\tlearn: 58.4744391\ttotal: 10.2s\tremaining: 14.6s\n",
      "139:\tlearn: 58.4428483\ttotal: 10.2s\tremaining: 14.5s\n",
      "140:\tlearn: 58.4051502\ttotal: 10.3s\tremaining: 14.4s\n",
      "141:\tlearn: 58.3855667\ttotal: 10.3s\tremaining: 14.3s\n",
      "142:\tlearn: 58.3055090\ttotal: 10.4s\tremaining: 14.3s\n",
      "143:\tlearn: 58.2253321\ttotal: 10.5s\tremaining: 14.2s\n",
      "144:\tlearn: 58.1210780\ttotal: 10.5s\tremaining: 14.1s\n",
      "145:\tlearn: 58.0834575\ttotal: 10.6s\tremaining: 14s\n",
      "146:\tlearn: 58.0459628\ttotal: 10.7s\tremaining: 13.9s\n",
      "147:\tlearn: 58.0020078\ttotal: 10.7s\tremaining: 13.9s\n",
      "148:\tlearn: 57.9510478\ttotal: 10.8s\tremaining: 13.8s\n",
      "149:\tlearn: 57.9268692\ttotal: 10.9s\tremaining: 13.7s\n",
      "150:\tlearn: 57.8979036\ttotal: 11s\tremaining: 13.7s\n",
      "151:\tlearn: 57.8569081\ttotal: 11.1s\tremaining: 13.7s\n",
      "152:\tlearn: 57.7681923\ttotal: 11.2s\tremaining: 13.6s\n",
      "153:\tlearn: 57.7124750\ttotal: 11.2s\tremaining: 13.5s\n",
      "154:\tlearn: 57.6794725\ttotal: 11.3s\tremaining: 13.4s\n",
      "155:\tlearn: 57.6536109\ttotal: 11.3s\tremaining: 13.3s\n",
      "156:\tlearn: 57.5789506\ttotal: 11.4s\tremaining: 13.2s\n",
      "157:\tlearn: 57.5678808\ttotal: 11.5s\tremaining: 13.2s\n",
      "158:\tlearn: 57.5320970\ttotal: 11.6s\tremaining: 13.1s\n",
      "159:\tlearn: 57.5074904\ttotal: 11.6s\tremaining: 13s\n",
      "160:\tlearn: 57.4754592\ttotal: 11.7s\tremaining: 12.9s\n",
      "161:\tlearn: 57.4413613\ttotal: 11.8s\tremaining: 12.9s\n",
      "162:\tlearn: 57.3981616\ttotal: 11.8s\tremaining: 12.8s\n",
      "163:\tlearn: 57.3686824\ttotal: 11.9s\tremaining: 12.7s\n",
      "164:\tlearn: 57.3286883\ttotal: 12s\tremaining: 12.6s\n",
      "165:\tlearn: 57.2743694\ttotal: 12.1s\tremaining: 12.6s\n",
      "166:\tlearn: 57.2290397\ttotal: 12.1s\tremaining: 12.5s\n",
      "167:\tlearn: 57.1838854\ttotal: 12.2s\tremaining: 12.4s\n",
      "168:\tlearn: 57.1338700\ttotal: 12.3s\tremaining: 12.3s\n",
      "169:\tlearn: 57.0882897\ttotal: 12.3s\tremaining: 12.3s\n",
      "170:\tlearn: 57.0373260\ttotal: 12.4s\tremaining: 12.2s\n",
      "171:\tlearn: 57.0078556\ttotal: 12.5s\tremaining: 12.1s\n",
      "172:\tlearn: 56.9702296\ttotal: 12.5s\tremaining: 12s\n",
      "173:\tlearn: 56.9308297\ttotal: 12.6s\tremaining: 11.9s\n",
      "174:\tlearn: 56.8941333\ttotal: 12.7s\tremaining: 11.9s\n",
      "175:\tlearn: 56.8478468\ttotal: 12.7s\tremaining: 11.8s\n",
      "176:\tlearn: 56.8264770\ttotal: 12.8s\tremaining: 11.7s\n",
      "177:\tlearn: 56.8064186\ttotal: 12.9s\tremaining: 11.7s\n",
      "178:\tlearn: 56.7569471\ttotal: 13s\tremaining: 11.6s\n",
      "179:\tlearn: 56.6733344\ttotal: 13s\tremaining: 11.5s\n",
      "180:\tlearn: 56.6017268\ttotal: 13.1s\tremaining: 11.5s\n",
      "181:\tlearn: 56.5430216\ttotal: 13.2s\tremaining: 11.4s\n",
      "182:\tlearn: 56.4680631\ttotal: 13.3s\tremaining: 11.3s\n",
      "183:\tlearn: 56.4093208\ttotal: 13.3s\tremaining: 11.2s\n",
      "184:\tlearn: 56.3916419\ttotal: 13.4s\tremaining: 11.1s\n",
      "185:\tlearn: 56.3329960\ttotal: 13.5s\tremaining: 11.1s\n",
      "186:\tlearn: 56.2663759\ttotal: 13.5s\tremaining: 11s\n",
      "187:\tlearn: 56.2367063\ttotal: 13.6s\tremaining: 10.9s\n",
      "188:\tlearn: 56.1844659\ttotal: 13.7s\tremaining: 10.9s\n",
      "189:\tlearn: 56.1400024\ttotal: 13.8s\tremaining: 10.8s\n",
      "190:\tlearn: 56.1070802\ttotal: 13.9s\tremaining: 10.8s\n",
      "191:\tlearn: 56.0589632\ttotal: 14s\tremaining: 10.7s\n",
      "192:\tlearn: 56.0116934\ttotal: 14s\tremaining: 10.6s\n",
      "193:\tlearn: 55.9325958\ttotal: 14.1s\tremaining: 10.6s\n",
      "194:\tlearn: 55.8808692\ttotal: 14.2s\tremaining: 10.5s\n",
      "195:\tlearn: 55.8443342\ttotal: 14.3s\tremaining: 10.4s\n",
      "196:\tlearn: 55.8043698\ttotal: 14.4s\tremaining: 10.4s\n",
      "197:\tlearn: 55.7678457\ttotal: 14.5s\tremaining: 10.3s\n",
      "198:\tlearn: 55.7123414\ttotal: 14.5s\tremaining: 10.2s\n",
      "199:\tlearn: 55.6396039\ttotal: 14.6s\tremaining: 10.1s\n",
      "200:\tlearn: 55.5780953\ttotal: 14.7s\tremaining: 10.1s\n",
      "201:\tlearn: 55.5379755\ttotal: 14.7s\tremaining: 9.98s\n",
      "202:\tlearn: 55.4490594\ttotal: 14.8s\tremaining: 9.91s\n",
      "203:\tlearn: 55.4093942\ttotal: 14.8s\tremaining: 9.83s\n",
      "204:\tlearn: 55.3711692\ttotal: 14.9s\tremaining: 9.77s\n",
      "205:\tlearn: 55.2935265\ttotal: 15s\tremaining: 9.71s\n",
      "206:\tlearn: 55.2492550\ttotal: 15.1s\tremaining: 9.63s\n",
      "207:\tlearn: 55.2063517\ttotal: 15.2s\tremaining: 9.56s\n",
      "208:\tlearn: 55.1663644\ttotal: 15.2s\tremaining: 9.48s\n",
      "209:\tlearn: 55.1041152\ttotal: 15.3s\tremaining: 9.4s\n",
      "210:\tlearn: 55.0637509\ttotal: 15.4s\tremaining: 9.32s\n",
      "211:\tlearn: 55.0186114\ttotal: 15.4s\tremaining: 9.24s\n",
      "212:\tlearn: 54.9690293\ttotal: 15.5s\tremaining: 9.17s\n",
      "213:\tlearn: 54.9021523\ttotal: 15.6s\tremaining: 9.09s\n",
      "214:\tlearn: 54.8663759\ttotal: 15.6s\tremaining: 9.01s\n",
      "215:\tlearn: 54.8228898\ttotal: 15.7s\tremaining: 8.93s\n",
      "216:\tlearn: 54.7801560\ttotal: 15.7s\tremaining: 8.85s\n",
      "217:\tlearn: 54.7526852\ttotal: 15.8s\tremaining: 8.77s\n",
      "218:\tlearn: 54.7266149\ttotal: 15.9s\tremaining: 8.71s\n",
      "219:\tlearn: 54.6473525\ttotal: 16s\tremaining: 8.64s\n",
      "220:\tlearn: 54.6149535\ttotal: 16s\tremaining: 8.56s\n",
      "221:\tlearn: 54.5550864\ttotal: 16.1s\tremaining: 8.48s\n",
      "222:\tlearn: 54.5178909\ttotal: 16.2s\tremaining: 8.41s\n",
      "223:\tlearn: 54.4598859\ttotal: 16.2s\tremaining: 8.34s\n",
      "224:\tlearn: 54.4080784\ttotal: 16.3s\tremaining: 8.26s\n",
      "225:\tlearn: 54.3898100\ttotal: 16.4s\tremaining: 8.18s\n",
      "226:\tlearn: 54.3562698\ttotal: 16.4s\tremaining: 8.1s\n",
      "227:\tlearn: 54.3273303\ttotal: 16.5s\tremaining: 8.03s\n",
      "228:\tlearn: 54.2702541\ttotal: 16.5s\tremaining: 7.95s\n",
      "229:\tlearn: 54.2100570\ttotal: 16.6s\tremaining: 7.87s\n",
      "230:\tlearn: 54.1367693\ttotal: 16.7s\tremaining: 7.79s\n",
      "231:\tlearn: 54.0883446\ttotal: 16.7s\tremaining: 7.72s\n",
      "232:\tlearn: 54.0285151\ttotal: 16.8s\tremaining: 7.64s\n",
      "233:\tlearn: 53.9633635\ttotal: 16.9s\tremaining: 7.57s\n",
      "234:\tlearn: 53.9150085\ttotal: 16.9s\tremaining: 7.49s\n",
      "235:\tlearn: 53.8506841\ttotal: 17s\tremaining: 7.42s\n",
      "236:\tlearn: 53.7985921\ttotal: 17.1s\tremaining: 7.34s\n",
      "237:\tlearn: 53.7463159\ttotal: 17.1s\tremaining: 7.26s\n",
      "238:\tlearn: 53.7152933\ttotal: 17.2s\tremaining: 7.19s\n",
      "239:\tlearn: 53.6306921\ttotal: 17.2s\tremaining: 7.12s\n",
      "240:\tlearn: 53.5892091\ttotal: 17.3s\tremaining: 7.04s\n",
      "241:\tlearn: 53.5400372\ttotal: 17.4s\tremaining: 6.97s\n",
      "242:\tlearn: 53.4926823\ttotal: 17.5s\tremaining: 6.9s\n",
      "243:\tlearn: 53.4581218\ttotal: 17.6s\tremaining: 6.83s\n",
      "244:\tlearn: 53.4292032\ttotal: 17.6s\tremaining: 6.76s\n",
      "245:\tlearn: 53.3668102\ttotal: 17.7s\tremaining: 6.69s\n",
      "246:\tlearn: 53.3166353\ttotal: 17.8s\tremaining: 6.62s\n",
      "247:\tlearn: 53.2817830\ttotal: 17.8s\tremaining: 6.54s\n",
      "248:\tlearn: 53.2050706\ttotal: 17.9s\tremaining: 6.47s\n",
      "249:\tlearn: 53.1785958\ttotal: 18s\tremaining: 6.42s\n",
      "250:\tlearn: 53.1238892\ttotal: 18.1s\tremaining: 6.35s\n",
      "251:\tlearn: 53.0937933\ttotal: 18.2s\tremaining: 6.28s\n",
      "252:\tlearn: 53.0757470\ttotal: 18.2s\tremaining: 6.2s\n",
      "253:\tlearn: 53.0307400\ttotal: 18.3s\tremaining: 6.13s\n",
      "254:\tlearn: 52.9829332\ttotal: 18.4s\tremaining: 6.05s\n",
      "255:\tlearn: 52.9485997\ttotal: 18.4s\tremaining: 5.97s\n",
      "256:\tlearn: 52.9117750\ttotal: 18.5s\tremaining: 5.9s\n",
      "257:\tlearn: 52.8992708\ttotal: 18.5s\tremaining: 5.82s\n",
      "258:\tlearn: 52.8352891\ttotal: 18.6s\tremaining: 5.75s\n",
      "259:\tlearn: 52.7937902\ttotal: 18.7s\tremaining: 5.67s\n",
      "260:\tlearn: 52.7360194\ttotal: 18.7s\tremaining: 5.6s\n",
      "261:\tlearn: 52.7180426\ttotal: 18.8s\tremaining: 5.53s\n",
      "262:\tlearn: 52.6878517\ttotal: 18.9s\tremaining: 5.45s\n",
      "263:\tlearn: 52.6428829\ttotal: 18.9s\tremaining: 5.38s\n",
      "264:\tlearn: 52.6265721\ttotal: 19s\tremaining: 5.31s\n",
      "265:\tlearn: 52.5948092\ttotal: 19.1s\tremaining: 5.23s\n",
      "266:\tlearn: 52.5672239\ttotal: 19.1s\tremaining: 5.16s\n",
      "267:\tlearn: 52.5233937\ttotal: 19.2s\tremaining: 5.08s\n",
      "268:\tlearn: 52.4922691\ttotal: 19.2s\tremaining: 5.01s\n",
      "269:\tlearn: 52.4626717\ttotal: 19.3s\tremaining: 4.93s\n",
      "270:\tlearn: 52.3746393\ttotal: 19.4s\tremaining: 4.86s\n",
      "271:\tlearn: 52.3476393\ttotal: 19.4s\tremaining: 4.79s\n",
      "272:\tlearn: 52.3294099\ttotal: 19.5s\tremaining: 4.72s\n",
      "273:\tlearn: 52.2994513\ttotal: 19.6s\tremaining: 4.65s\n",
      "274:\tlearn: 52.2664970\ttotal: 19.7s\tremaining: 4.58s\n",
      "275:\tlearn: 52.2250632\ttotal: 19.8s\tremaining: 4.51s\n",
      "276:\tlearn: 52.1940000\ttotal: 19.8s\tremaining: 4.44s\n",
      "277:\tlearn: 52.1431188\ttotal: 19.9s\tremaining: 4.37s\n",
      "278:\tlearn: 52.1209042\ttotal: 20s\tremaining: 4.3s\n",
      "279:\tlearn: 52.0728832\ttotal: 20.1s\tremaining: 4.24s\n",
      "280:\tlearn: 52.0510452\ttotal: 20.2s\tremaining: 4.17s\n",
      "281:\tlearn: 52.0177870\ttotal: 20.3s\tremaining: 4.1s\n",
      "282:\tlearn: 52.0000011\ttotal: 20.3s\tremaining: 4.03s\n",
      "283:\tlearn: 51.9607808\ttotal: 20.4s\tremaining: 3.95s\n",
      "284:\tlearn: 51.8925857\ttotal: 20.5s\tremaining: 3.88s\n",
      "285:\tlearn: 51.8421995\ttotal: 20.5s\tremaining: 3.81s\n",
      "286:\tlearn: 51.7909672\ttotal: 20.6s\tremaining: 3.74s\n",
      "287:\tlearn: 51.7659264\ttotal: 20.7s\tremaining: 3.66s\n",
      "288:\tlearn: 51.7218149\ttotal: 20.8s\tremaining: 3.59s\n",
      "289:\tlearn: 51.6423028\ttotal: 20.8s\tremaining: 3.52s\n",
      "290:\tlearn: 51.6276088\ttotal: 20.9s\tremaining: 3.44s\n",
      "291:\tlearn: 51.5949630\ttotal: 20.9s\tremaining: 3.37s\n",
      "292:\tlearn: 51.5599464\ttotal: 21s\tremaining: 3.3s\n",
      "293:\tlearn: 51.5106879\ttotal: 21.1s\tremaining: 3.22s\n",
      "294:\tlearn: 51.4883656\ttotal: 21.1s\tremaining: 3.15s\n",
      "295:\tlearn: 51.4510395\ttotal: 21.2s\tremaining: 3.08s\n",
      "296:\tlearn: 51.4137347\ttotal: 21.3s\tremaining: 3.01s\n",
      "297:\tlearn: 51.3755153\ttotal: 21.3s\tremaining: 2.93s\n",
      "298:\tlearn: 51.3595810\ttotal: 21.4s\tremaining: 2.86s\n",
      "299:\tlearn: 51.3237636\ttotal: 21.4s\tremaining: 2.79s\n",
      "300:\tlearn: 51.2933818\ttotal: 21.5s\tremaining: 2.71s\n",
      "301:\tlearn: 51.2373822\ttotal: 21.6s\tremaining: 2.64s\n",
      "302:\tlearn: 51.2041202\ttotal: 21.6s\tremaining: 2.57s\n",
      "303:\tlearn: 51.1789295\ttotal: 21.7s\tremaining: 2.5s\n",
      "304:\tlearn: 51.1216969\ttotal: 21.8s\tremaining: 2.42s\n",
      "305:\tlearn: 51.0614675\ttotal: 21.8s\tremaining: 2.35s\n",
      "306:\tlearn: 51.0341756\ttotal: 21.9s\tremaining: 2.28s\n",
      "307:\tlearn: 51.0180639\ttotal: 22s\tremaining: 2.21s\n",
      "308:\tlearn: 50.9850414\ttotal: 22.1s\tremaining: 2.15s\n",
      "309:\tlearn: 50.9196126\ttotal: 22.2s\tremaining: 2.08s\n",
      "310:\tlearn: 50.8632322\ttotal: 22.3s\tremaining: 2s\n",
      "311:\tlearn: 50.8035336\ttotal: 22.3s\tremaining: 1.93s\n",
      "312:\tlearn: 50.7749700\ttotal: 22.4s\tremaining: 1.86s\n",
      "313:\tlearn: 50.7283345\ttotal: 22.5s\tremaining: 1.79s\n",
      "314:\tlearn: 50.7071751\ttotal: 22.5s\tremaining: 1.72s\n",
      "315:\tlearn: 50.6686299\ttotal: 22.6s\tremaining: 1.65s\n",
      "316:\tlearn: 50.6075438\ttotal: 22.7s\tremaining: 1.57s\n",
      "317:\tlearn: 50.5667814\ttotal: 22.7s\tremaining: 1.5s\n",
      "318:\tlearn: 50.5082249\ttotal: 22.8s\tremaining: 1.43s\n",
      "319:\tlearn: 50.4431419\ttotal: 22.9s\tremaining: 1.36s\n",
      "320:\tlearn: 50.4140660\ttotal: 22.9s\tremaining: 1.28s\n",
      "321:\tlearn: 50.3844995\ttotal: 23s\tremaining: 1.21s\n",
      "322:\tlearn: 50.3514188\ttotal: 23.1s\tremaining: 1.14s\n",
      "323:\tlearn: 50.3002974\ttotal: 23.1s\tremaining: 1.07s\n",
      "324:\tlearn: 50.2485268\ttotal: 23.2s\tremaining: 1000ms\n",
      "325:\tlearn: 50.2262640\ttotal: 23.3s\tremaining: 928ms\n",
      "326:\tlearn: 50.2094382\ttotal: 23.4s\tremaining: 857ms\n",
      "327:\tlearn: 50.1487879\ttotal: 23.4s\tremaining: 785ms\n",
      "328:\tlearn: 50.1010254\ttotal: 23.5s\tremaining: 714ms\n",
      "329:\tlearn: 50.0558944\ttotal: 23.6s\tremaining: 643ms\n",
      "330:\tlearn: 50.0182316\ttotal: 23.6s\tremaining: 571ms\n",
      "331:\tlearn: 49.9995415\ttotal: 23.7s\tremaining: 500ms\n",
      "332:\tlearn: 49.9279848\ttotal: 23.8s\tremaining: 428ms\n",
      "333:\tlearn: 49.9041283\ttotal: 23.8s\tremaining: 357ms\n",
      "334:\tlearn: 49.8673989\ttotal: 23.9s\tremaining: 286ms\n",
      "335:\tlearn: 49.8410291\ttotal: 24s\tremaining: 214ms\n",
      "336:\tlearn: 49.7997345\ttotal: 24.1s\tremaining: 143ms\n",
      "337:\tlearn: 49.7656947\ttotal: 24.1s\tremaining: 71.4ms\n",
      "338:\tlearn: 49.7226311\ttotal: 24.2s\tremaining: 0us\n",
      "R²: 0.5648346043803275\n",
      "MAE: 40.90479591232284\n",
      "MSE: 3893.1037876720716\n",
      "RMSE: 62.39474166684298\n",
      "MAPE: 0.3169895341922205\n",
      "error_ratio_rmse: 0.45112412163675525\n",
      "error_ratio_mae: 0.29574832163274284\n",
      "\n",
      "--- Homemade Voting ---\n",
      "\n",
      "\n",
      "R²: 0.5732510782371074\n",
      "MAE: 40.506391661338164\n",
      "MSE: 3817.8078046263286\n",
      "RMSE: 61.78841157228699\n",
      "MAPE: 0.3143592027174954\n",
      "error_ratio_rmse: 0.4467402565221432\n",
      "error_ratio_mae: 0.29286779415590064\n",
      "\n",
      "--- Homemade Stacking ---\n",
      "\n",
      "\n",
      "R2 : 0.574005685903686\n",
      "MAE : 40.40949897945306\n",
      "MSE : 3811.056886482252\n",
      "RMSE : 61.733758078398665\n",
      "MAPE : 0.31209301850892385\n",
      "error_ratio_rmse : 0.4463451028799277\n",
      "error_ratio_mae : 0.2921672443204379\n",
      "\n",
      "--- sklearn Stacking ---\n",
      "\n",
      "\n",
      "R2 : 0.5500372782874432\n",
      "MAE : 41.36670545044114\n",
      "MSE : 4025.484548733263\n",
      "RMSE : 63.44670636631395\n",
      "MAPE : 0.31731717761246064\n",
      "error_ratio_rmse : 0.4587299973622397\n",
      "error_ratio_mae : 0.29908800265541446\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "model_names = [('Decision Tree',decision_tree),\n",
    "                ('Bagging',bagging),\n",
    "                ('Random Forest',random_forest),\n",
    "                ('Extremely Randomized Forest',extra_forest),\n",
    "                ('Adaboost',adaboost),\n",
    "                ('sklearn Gradient Boosting',sk_gb),\n",
    "                ('sklearn Hist Gradient Boosting',hist_sk_gb),\n",
    "                ('LightGBM',lgbm),\n",
    "                ('XGBoost',xgb),\n",
    "               ('CatBoost', catboost)\n",
    "               ]\n",
    "\n",
    "for i in range(len(model_names)) :\n",
    "    print('')\n",
    "    print('')\n",
    "    print('--- '+model_names[i][0]+' ---')\n",
    "    print('')\n",
    "    model = model_names[i][1]\n",
    "    model.fit(X_train_np, y_train_np)\n",
    "    y_pred = np.maximum(0,model.predict(X_test_np))\n",
    "    score = scores(y_test_np,y_pred,plot=False)\n",
    "    score['Model'] = model_names[i][0]\n",
    "    all_scores.append(score)\n",
    "\n",
    "print('')\n",
    "print('--- Homemade Voting ---')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "y_pred = vote_prediction(vote_estimators,X_train_np,y_train_np,X_test_np, weights_normalized)\n",
    "score = scores(y_test_np,y_pred,plot=False)\n",
    "score['Model'] = 'Homemade Voting'\n",
    "all_scores.append(score)\n",
    "\n",
    "print('')\n",
    "print('--- Homemade Stacking ---')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "for key in homemade_stacking_scores:\n",
    "    print(key,':', homemade_stacking_scores[key])\n",
    "homemade_stacking_scores['Model'] = 'Homemade stacking'\n",
    "all_scores.append(homemade_stacking_scores)\n",
    "\n",
    "print('')\n",
    "print('--- sklearn Stacking ---')\n",
    "print('')\n",
    "print('')\n",
    "for key in sk_stacking_scores:\n",
    "    print(key,':', sk_stacking_scores[key])\n",
    "sk_stacking_scores['Model'] = 'sklearn Stacking'\n",
    "all_scores.append(sk_stacking_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>error_ratio_rmse</th>\n",
       "      <th>error_ratio_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Homemade stacking</td>\n",
       "      <td>0.574006</td>\n",
       "      <td>40.409499</td>\n",
       "      <td>3811.056886</td>\n",
       "      <td>61.733758</td>\n",
       "      <td>0.312093</td>\n",
       "      <td>0.446345</td>\n",
       "      <td>0.292167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Homemade Voting</td>\n",
       "      <td>0.573251</td>\n",
       "      <td>40.506392</td>\n",
       "      <td>3817.807805</td>\n",
       "      <td>61.788412</td>\n",
       "      <td>0.314359</td>\n",
       "      <td>0.446740</td>\n",
       "      <td>0.292868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>40.756571</td>\n",
       "      <td>3847.962707</td>\n",
       "      <td>62.031949</td>\n",
       "      <td>0.315426</td>\n",
       "      <td>0.448501</td>\n",
       "      <td>0.294677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.567503</td>\n",
       "      <td>40.893731</td>\n",
       "      <td>3869.227835</td>\n",
       "      <td>62.203118</td>\n",
       "      <td>0.316006</td>\n",
       "      <td>0.449739</td>\n",
       "      <td>0.295668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.564835</td>\n",
       "      <td>40.904796</td>\n",
       "      <td>3893.103788</td>\n",
       "      <td>62.394742</td>\n",
       "      <td>0.316990</td>\n",
       "      <td>0.451124</td>\n",
       "      <td>0.295748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.562745</td>\n",
       "      <td>41.077431</td>\n",
       "      <td>3911.796941</td>\n",
       "      <td>62.544360</td>\n",
       "      <td>0.322141</td>\n",
       "      <td>0.452206</td>\n",
       "      <td>0.296996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extremely Randomized Forest</td>\n",
       "      <td>0.561750</td>\n",
       "      <td>41.069603</td>\n",
       "      <td>3920.700182</td>\n",
       "      <td>62.615495</td>\n",
       "      <td>0.325224</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.296940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn Hist Gradient Boosting</td>\n",
       "      <td>0.559020</td>\n",
       "      <td>41.267632</td>\n",
       "      <td>3945.121306</td>\n",
       "      <td>62.810201</td>\n",
       "      <td>0.319405</td>\n",
       "      <td>0.454128</td>\n",
       "      <td>0.298372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>41.776126</td>\n",
       "      <td>3985.585007</td>\n",
       "      <td>63.131490</td>\n",
       "      <td>0.332119</td>\n",
       "      <td>0.456451</td>\n",
       "      <td>0.302048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sklearn Stacking</td>\n",
       "      <td>0.550037</td>\n",
       "      <td>41.366705</td>\n",
       "      <td>4025.484549</td>\n",
       "      <td>63.446706</td>\n",
       "      <td>0.317317</td>\n",
       "      <td>0.458730</td>\n",
       "      <td>0.299088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn Gradient Boosting</td>\n",
       "      <td>0.535991</td>\n",
       "      <td>42.522334</td>\n",
       "      <td>4151.144567</td>\n",
       "      <td>64.429377</td>\n",
       "      <td>0.337570</td>\n",
       "      <td>0.465835</td>\n",
       "      <td>0.307443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.478077</td>\n",
       "      <td>45.825598</td>\n",
       "      <td>4669.256527</td>\n",
       "      <td>68.331958</td>\n",
       "      <td>0.371195</td>\n",
       "      <td>0.494051</td>\n",
       "      <td>0.331327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.426036</td>\n",
       "      <td>48.832359</td>\n",
       "      <td>5134.831774</td>\n",
       "      <td>71.657741</td>\n",
       "      <td>0.403429</td>\n",
       "      <td>0.518097</td>\n",
       "      <td>0.353066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model        R2        MAE          MSE  \\\n",
       "11               Homemade stacking  0.574006  40.409499  3811.056886   \n",
       "10                 Homemade Voting  0.573251  40.506392  3817.807805   \n",
       "8                          XGBoost  0.569880  40.756571  3847.962707   \n",
       "7                         LightGBM  0.567503  40.893731  3869.227835   \n",
       "9                         CatBoost  0.564835  40.904796  3893.103788   \n",
       "2                    Random Forest  0.562745  41.077431  3911.796941   \n",
       "3      Extremely Randomized Forest  0.561750  41.069603  3920.700182   \n",
       "6   sklearn Hist Gradient Boosting  0.559020  41.267632  3945.121306   \n",
       "1                          Bagging  0.554497  41.776126  3985.585007   \n",
       "12                sklearn Stacking  0.550037  41.366705  4025.484549   \n",
       "5        sklearn Gradient Boosting  0.535991  42.522334  4151.144567   \n",
       "0                    Decision Tree  0.478077  45.825598  4669.256527   \n",
       "4                         Adaboost  0.426036  48.832359  5134.831774   \n",
       "\n",
       "         RMSE      MAPE  error_ratio_rmse  error_ratio_mae  \n",
       "11  61.733758  0.312093          0.446345         0.292167  \n",
       "10  61.788412  0.314359          0.446740         0.292868  \n",
       "8   62.031949  0.315426          0.448501         0.294677  \n",
       "7   62.203118  0.316006          0.449739         0.295668  \n",
       "9   62.394742  0.316990          0.451124         0.295748  \n",
       "2   62.544360  0.322141          0.452206         0.296996  \n",
       "3   62.615495  0.325224          0.452720         0.296940  \n",
       "6   62.810201  0.319405          0.454128         0.298372  \n",
       "1   63.131490  0.332119          0.456451         0.302048  \n",
       "12  63.446706  0.317317          0.458730         0.299088  \n",
       "5   64.429377  0.337570          0.465835         0.307443  \n",
       "0   68.331958  0.371195          0.494051         0.331327  \n",
       "4   71.657741  0.403429          0.518097         0.353066  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Results = pd.DataFrame(all_scores)\n",
    "Final_Results = Final_Results[['Model','R2','MAE','MSE','RMSE','MAPE','error_ratio_rmse','error_ratio_mae']] \n",
    "Final_Results.sort_values('R2',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Our homemade stacking and voting algorithms showed the best results on all metrics, with XGBoost completing the top three.\n",
    "\n",
    "sklearn Stacking performed poorly compared to the homemade, most probably due to the fact that the meta feature matrix cannot be appended to the initial features in sklearn's implementation.\n",
    "\n",
    "This project was interesting as it allowed us to experiment and tune many different ensemble techniques and implement several algorithms and feature engineering approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03306723d88c9fb7e2d96c1da74f103156186c5988cb13ed43a8356b89897714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
